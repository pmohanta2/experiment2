{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import xception\n",
    "\n",
    "\n",
    "class FacialExpressionRecognizer():\n",
    "    \"\"\"\n",
    "    Class for facial expression recognition\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        Args:\n",
    "            model_path (str): path to facial expression recognizer model\n",
    "        \"\"\"\n",
    "        # load pre trained facial expression recognizer model\n",
    "        self.model: keras.Model = keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "    def pre_process_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Method to preprocess image for model\n",
    "        Args:\n",
    "            img (np.ndarray): image\n",
    "        Returns:\n",
    "            np.ndarray: preprocessed image\n",
    "        \"\"\"\n",
    "        # resize image\n",
    "        preprocessed_img: np.ndarray = cv2.resize(img, (96,96))\n",
    "        # transfrom image to grayscale\n",
    "        preprocessed_img: np.ndarray = cv2.cvtColor(preprocessed_img,\n",
    "                                                    cv2.COLOR_BGR2GRAY)\n",
    "        # create 3 dimension grayscale image\n",
    "        preprocessed_img: np.ndarray = cv2.cvtColor(preprocessed_img,\n",
    "                                                    cv2.COLOR_GRAY2RGB)\n",
    "        # preprocess image\n",
    "        preprocessed_img: np.ndarray = xception.preprocess_input(\n",
    "            preprocessed_img)\n",
    "        return preprocessed_img\n",
    "    \n",
    "\n",
    "    def get_facial_expression_value(self, img: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        method to get image facial expression value\n",
    "        Args:\n",
    "            img (np.ndarray): image\n",
    "        Returns:\n",
    "            int: number between 0-6\n",
    "        \"\"\"\n",
    "        return np.argmax(self.model.predict(np.asarray([img])),\n",
    "                         axis=-1)[0]\n",
    "\n",
    "\n",
    "    def get_facial_expression_label(self, img: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        method to get image facial expression label\n",
    "        Args:\n",
    "            img (np.ndarray): image\n",
    "        Returns:\n",
    "            str: facial expression label\n",
    "        \"\"\"\n",
    "        # map of emotion value to string \n",
    "        emotion_map: Dict[int,str] = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\",\n",
    "                                      3:\"Happy\", 4:\"Sad\", 5:\"Surprise\",\n",
    "                                      6:\"Neutral\"}\n",
    "        return emotion_map[self.get_facial_expression_value(img)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
